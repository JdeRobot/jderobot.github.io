---
permalink: /activities/gsoc/2022
title: "GSoC 2022"

youtubeId1: wmAeoyiUyh4
youtubeId2: 07RnI9bXysk
youtubeId3: Y5VvQAP6cMI
youtubeId4: AGJlCJ6UXPs
youtubeId5: gDP9nWCL0Vg
youtubeId6: kJMPz80w9BM
youtubeId7: rDgVL0QYF_o
youtubeId8: ufvPS5wJAx0
youtubeId9: y7rBPpV2NdI
youtubeId10: BpHSDrFqpVk
youtubeId11: yKXP3UIAxtg
youtubeId12: tzxxEyA-LWs
youtubeId13: s-S5mQp9i1Y
youtubeId14: 4yKM3EuEv_g
youtubeId15: NrzmH_yerBU
youtubeId16: 97JRYhKLhSY
youtubeId41: W3XirsadmNg
youtubeId50: 7s4vpMGU2Mg

sidebar:
  nav: "docs"

toc: true
toc_label: "TOC GSoC-2022"
toc_icon: "cog"

projects:


---

Robotics applications are typically distributed, made up of a collection of concurrent asynchronous components which communicate using some middleware (ROS messages, DDS...). Building robotics applications is a complex task. Integrating existing nodes or libraries that provide already solved functionality, and using several tools may increase the software robustness and shorten the development time. JdeRobot provides several tools, libraries and reusable nodes. They have been written in C++, Python or JavaScript. They are ROS-friendly and full compatible with ROS-Noetic, ROS2-Foxy (and Gazebo11).


Our community mainly works on four development areas:
- Education in Robotics. [RoboticsAcademy](https://jderobot.github.io/RoboticsAcademy/) is our main project. It is a ROS-based framework to learn robotics and computer vision with drones, autonomous cars.... It is a collection of Python programmed exercises for engineering students. 

- Robot Programming Tools. For instance, [VisualCircuit](https://jderobot.github.io/VisualCircuit/) for robot programming with connected blocks, as in eleectronic circuits, in a visual way.

- MachineLearning in Robotics. For instance, [DeepLearningStudio](https://github.com/JdeRobot/DeepLearningStudio) to explore the use neural networks for robot control. It includes the [BehaviorMetrics tool](https://jderobot.github.io/BehaviorMetrics/) for assessment of neural networks for autonomous driving. [RL-Studio](https://github.com/JdeRobot/RL-Studio), a library for the training of Reinforcement Learning algorithms for robot control. [DetectionMetrics tool](https://github.com/JdeRobot/DetectionMetrics) for evaluation of visual detection neural networks and algorithms.

- Reconfigurable Computing in Robotics. [FPGA-Robotics](https://github.com/JdeRobot/FPGA-robotics) for programming robots with reconfigurable computing (FPGAs) using open tools as IceStudio and Symbiflow. Verilog-based reusable blocks for robotics applications.




# Selected students




# Ideas list

JdeRobot simplifies the access to hardware devices from the control program. Getting sensor measurements is as simple as calling a local function, and ordering motor commands as easy as calling another local function. The platform attaches those calls to the remote invocation on the components connected to the sensor or the actuator devices. They can be connected to real sensors and actuators or simulated ones, both locally or remotely using the network. Those functions build the API for the Hardware Abstraction Layer. The robotic application get the sensor readings and order the actuator commands using it to unfold its behavior. Several driver components have been developed to support different physical sensors, actuators and simulators. The drivers are used as components installed at will depending on your configuration. They are included in the official release.

This open source project needs further development in these topics:


## Project #1: Robotics Academy: optimization of exercise templates

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. Up until now, the students had to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision.

For each exercise there is a webpage (exercise.html) and a Python template (exercise.py), both connected through websockets. Exercise.py typically connects to the robot sensors and actuators in the Gazebo simulator, connects to the webpage to show the Graphical User Interface and runs the robot's brain. That brain has been edited by the user at the webpage. Currently it is based in Python Threading, one possible optimization is to implement it with subprocesses or Python Multiprocessing to take full advantage of the multiple cores of user computer. Another desired optimization is to make full use of the GPU acceleration at user computer from the docker container of RoboticsAcademy.

{% include youtubePlayer.html id=page.youtubeId7 %}

{% include youtubePlayer.html id=page.youtubeId9 %}

- **Expected results:** more fluent execution of RoboticsAcademy exercises
- **Knowledge Prerequisite:** Python programming skills
- **Mentors:** David Roldán (david.roldan AT urjc.es) and Sakshay Mahna ( sakshum19 AT gmail.com )



## Project #2: Robotics Academy: consolidation of drone based exercises

**Brief Explanation**: JdeRobot’s [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It  consists of a collection of robot programming exercises using Python language where the student has to code the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. It uses standard middleware and libraries as ROS and openCV, so the student learn the state of the art tools.

Currently there are [9 drone exercises](https://jderobot.github.io/RoboticsAcademy/exercises/drones_section) available in web-templates version (v3.2) and two are about to come. Project's goal is to consolidate the existing exercises, improving front-end appealing and extending drones back-end with new functionability as adding support to new control methods or new sensors (IR, depth cameras, etc). The project may also explore the develompent of new exercises or extending support to real drones.

You will work with Docker, Gazebo-11 and ROS-noetic. Also, ROS2 use for these exercises will be explored.

<figure class="half">
    <a href=""><iframe src="https://www.youtube.com/embed/fISm9Q2_ogg"></iframe></a>
    <a href=""><iframe src="https://www.youtube.com/embed/0dV8OkTG0pM"></iframe></a>
 </figure>

- **Expected results:** ROS-based drones exercises.
- **Project size:** Medium size (~175h).
- **Knowledge Prerequisite:** Python, OpenCV, ROS, HTML, CSS and Django.
- **Project difficulty:** Medium.
- **Mentors:** Pedro Arias (pedroariasperez96 AT gmail.com)

## Project #3: Robotics Academy: improve autonomous driving exercises

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. Up until now, the students had to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision.

Currently there are four exercises regarding autonomous driving exercises in RoboticsAcademy: [local navigation](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/obstacle_avoidance), [global navigation](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/global_navigation/), [autoparking](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/autoparking/) and [car junction](https://jderobot.github.io/RoboticsAcademy/exercises/AutonomousCars/car_junction/). The car models have to be improved to be more realistic, use Ackerman control and LIDAR sensor onboard. ROS2 use for these exercises will be explored.

{% include youtubePlayer.html id=page.youtubeId10 %}

{% include youtubePlayer.html id=page.youtubeId16 %}

- **Expected results:** ROS-based autonomous driving exercises 
- **Knowledge Prerequisite:** Python programming skills, Gazebo.
- **Mentors:** Luis Roberto Morales (lr.morales.iglesias AT gmail.com), José María Cañas (josemaria.plaza AT gmail.com)


## Project #4: Robotics-Academy: exercise using Deep Learning for Visual Detection

**Brief Explanation**: JdeRobot’s [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. Up until now, the students had to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. 

The idea for this project is to develop a new deep learning exercise within the Robotics-Academy context. More specifically, we will be building a template for visual detection exercises (e.g. human pose estimation or traffic sign recognition) that must be solved by providing a trained model for the particular task. In that way, instead of asking the user to code the solution in a web-based editor, he or she will have to upload a deep learning model that matches our defined set of inputs (e.g. single or multiple images) and outputs (e.g. 2D coordinates). In this project, we will be:
- Updating our web interface for accepting models trained with PyTorch/Tensorflow as input.
- Building new widgets for monitoring results for the particular exercise.
- Coding the core application that will feed the trained model with input data and return the result.
- Training a naïve model that allow us to show how the exercise can be solved.

In the following videos examples of one of our current web-based exercises and a visual detection task solved using deep learning are shown: 

{% include youtubePlayer.html id=page.youtubeId14 %}

{% include youtubePlayer.html id=page.youtubeId41 %}


- **Expected results:** a web-based exercise for solving a visual detection task using deep learning
- **Knowledge Prerequisite:** Python, OpenCV, PyTorch/Tensorflow
- **Mentors:** David Pascual ( d.pascualhe AT gmail.com ) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)

## Project #5: Robotics-Academy: exercise using Deep Learning for Visual Control

**Brief Explanation**: [Robotics-Academy](https://jderobot.github.io/RoboticsAcademy) is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. Up until now, the students had to code in Python the behavior of a given (either simulated or real) robot to fit some task related to robotics or computer vision. 

The idea for this project is to develop a new deep learning exercise for visual robotic control within the Robotics-Academy context. In that sense, we will be building a web-based interface that allows the user to input a trained model that matches our defined input (e.g. a camera installed on a drone) and outputs (e.g. linear speed and angular velocity). The controlled robot and its environment will be simulated using Gazebo. In this project, we will be:
- Updating our web interface for accepting models trained with PyTorch/Tensorflow as input.
- Building new widgets for monitoring results for the particular exercise.
- Getting a simulated environment ready.
- Coding the core application that will feed the trained model with input data and send back the results.
- Training a naïve model that allow us to show how the exercise can be solved.

In the following videos examples of one of our current web-based exercises and a visual control task solved using deep learning are shown:

{% include youtubePlayer.html id=page.youtubeId14 %}

{% include youtubePlayer.html id=page.youtubeId50 %}

- **Expected results:** a web-based exercise for robotic visual control using deep learning
- **Knowledge Prerequisite:** Python, OpenCV, PyTorch/Tensorflow, Gazebo
- **Mentors:** David Pascual ( d.pascualhe AT gmail.com ) and Pankhuri Vanjani (pankhurivanjani AT gmail.com)

## Project #6: Robotics-Academy: Web template improvements to use state of the art frontend technologies.

**Brief Explanation**: JdeRobot’s Robotics-Academy is a framework for learning robotics and computer vision. It consists of a collection of robot programming exercises. Up until now, the users had to install all the necessary dependencies in their own computers for each exercise they wanted to run. In the last year, the Robotics-Academy group has worked towards the use of a Docker image with all the dependencies already installed in it and the use of Web-templates. 

Web-templates consist of the use of the web browser as the user interface. The browser connects with the Docker image application in order to run the simulation and to allow the users to send their code and see the results of the simulation.
Nowadays, the Web-templates have been developed using plain HTML, Javascript and CSS and we believe that there is potential improvementes to the interfacte by using advanced frontend technologies such as React, Vue, Angular or Flutter. 

[![Color filter](https://img.youtube.com/vi/Fv9s99IEIvc/0.jpg)](https://www.youtube.com/watch?v=Fv9s99IEIvc)
[![Drone template](http://img.youtube.com/vi/LIB1xCeXgf4/0.jpg)](http://www.youtube.com/watch?v=LIB1xCeXgf4 "https://www.youtube.com/watch?v=Xcy84DhVjrY")

- **Expected results:** Upgrade the current Web-templates to use a more advanced frontend technologies.
- **Knowledge Prerequisite:** Python, JavaScript, HTML, CSS
- **Mentors:** David Roldán (david.roldan AT urjc.es) and Jose María Cañas (josemaria.plaza AT urjc.es)


## Project #7: Shifting VisualCircuit to a web server

**Brief Explanation**: VisualCircuit allows users to program robotic intelligence using a visual language which consists of blocks and wires, as electronic circuits. We want to shift this tool from a desktop application to an online web server so anyone can try it out without going through the process of installation. The main area of focus would be on the frontend. The current desktop release is based on NodeJS and Electron. We want to shift that to a web server using Django. So basically you will need to develop a UI similar to the one in the current release which synthesizes that circuit into a .vc file (JSON file) which is then read by a local machine using the Python backend (already developed). You can read further about the tool on the [website](https://jderobot.github.io/VisualCircuit/documentation/). In this way, VisualCircuit will be cross-platform, attract new users and be very convenient to use. 

**Requirements:**

- A Dockerfile for installation of required dependencies on a local machine.
- A Small UI wrapper around the current Python backend that can execute updated circuits on a local machine. 
- Shifting VisualCircuit to the web.
- Users can create an account which provides online storage to save their design files.

**Automated Build on Local Machine through the Website:**
Web server → Downloaded circuit file → Check for updated .vc file (WatchDog) → Execute updated file

 <img src="/assets/images/activities/gsoc/VisualCircuit.png" width="60%" height="60%">

<!--
<figure class="half">
  <img src="/assets/images/activities/gsoc/fpga-circuit.png" width="50%" height="60%">
  <img src="/assets/images/activities/gsoc/icestudio.png" width="50%" height="60%">
  <figcaption>VisualCircuit</figcaption>
</figure>
-->

- **Expected results:** An online working release on VisualCircuit on a Web Server.
- **Knowledge Prerequisite:** Python, Django and some basic JavaScript knowledge..
- **Mentors:** Muhammad Taha (mtsg09 AT gmail.com) and JoséMaría Cañas (josemaria.plaza AT urjc.es)



## Project #8: Deep Learning model optimization for autonomous driving

**Brief explanation**: [Behavior Studio](https://jderobot.github.io/BehaviorStudio/) is a tool used to compare different
 autonomous driving architectures. It uses [Gazebo](http://gazebosim.org/), a well-known really
 powerful robotics simulator and [ROS Noetic](http://wiki.ros.org/noetic). 

We are currently able to drive autonomously on different circuits using deep learning models to do the robot control processing. 
Check out the videos below to get an insight. 

For this project, we would like to improve the current model stack based on deep learning, applying some optimization techniques to 
make them run faster without losing precision. Since the hardware devices used to do the inference in real world scenarios usually have  
a small amount of compute capabilities, we would like to apply speed up techniques on our models or explore new model architectures
with low inference time. Some references:

* [TensorRT](https://developer.nvidia.com/tensorrt)
* [Quantization](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize)

<figure class="half">
    <a href=""><iframe src="https://www.youtube.com/embed/h_-vlBH-hBE"></iframe></a>
    <a href=""><iframe src="https://www.youtube.com/embed/J6bDlE7TofE"></iframe></a>
 </figure>

- **Expected results:** New autonomous driving deep learning models with lower inference time.
- **Knowledge Prerequisites:** Python and deep learning knowledge (Tensorflow/PyTorch).
- **Mentors:** Sergio Paniego Blanco (sergiopaniegoblanco AT gmail.com)

## Project #9: Autonomous driving drone further support with Gazebo using deep learning techniques

**Brief Explanation**:  [Behavior Studio](https://jderobot.github.io/BehaviorStudio/) is a tool used to compare different
 autonomous driving architectures. It uses [Gazebo](http://gazebosim.org/), a well-known really
 powerful robotics simulator and [ROS Noetic](http://wiki.ros.org/noetic). 

During a past GSoC 2021 [project](https://theroboticsclub.github.io/gsoc2021-Utkarsh_Mishra/gsoc/Summary-and-Recap/), we explored
the addition of drone support for Behavior Metrics. We were able to add this support for IRIS drone, so we would like to keep exploring
adding autonomous driving techniques support based on deep learning for this configuration. 

We would like to generate new drone scenarios
specially suited for the robot control problem, train deep learning models based on state of the art architectures and add this support to 
the Behavior Metrics stack.


<figure class="half">
    <a href=""><iframe src="https://www.youtube.com/embed/GZs6OIQ_az0"></iframe></a>
    <a href=""><iframe src="https://www.youtube.com/embed/pbYfdXvtRLo"></iframe></a>
 </figure>

- **Expected results:** Broader support for the autonomous driving drone using Gazebo and PyTorch.
- **Knowledge Prerequisites:** Python and deep learning knowledge (specially PyTorch).
- **Mentors:** Sergio Paniego Blanco (sergiopaniegoblanco AT gmail.com)


## Project #10: Robotics Academy: multirobot version of the Amazon warehouse exercise in ROS2

**Brief Explanation**: Swarm robots have gained the importance in the domain of Intelligent Systems with their applications being extended to warehouses. One such popular multi-robot systems could be found in Amazon warehouses, from where this project borrows its inspiration. The goal of this project is to build a multi-robot navigation exercise extending the already existing Amazon warehouse exercise (demonstrated in video) to a fleet of robots and migrating its infrastructure to ROS2.


{% include youtubePlayer.html id=page.youtubeId1 %}


ROS2 has put forward several improvements over ROS with changes in middleware and software architecture in many aspects. One of its target applications is multi-robot agents. In this project, we would focus on developing new exercises with ROS2 for multi robots (starting with 2 - 3 robots and then increasing complexity). The Navigation stack of ROS2 introduces better features to implement control of a swarm of robots. with a support for multiple robots in the same ROS domain, navigating independently.  The idea is to use the ROS2 navigation stack for the control system and planning to create new robotics exercises for JdeRobot Academy. This will involve the use of functionalities such as collision avoidance between robots, global path planning, and Multi-robot coordination for developing application based exercises.

For more information on ROS2 based exercises, have a look at [GSoC 2020 project](https://theroboticsclub.github.io/colab-gsoc2020-Shreyas_Gokhale/) and corresponding academy exercises [1](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/single_robot_amazon_warehouse/) and [2](https://jderobot.github.io/RoboticsAcademy/exercises/MobileRobots/multi_robot_amazon_warehouse/). 


- **Expected results:** A new multirobot exercise in JdeRobot-Academy
- **Knowledge Prerequisite:** C++, Python programming skills, experience with ROS.
- **Good to know:*** ROS2
- **Mentors:** Pankhuri Vanjani (pankhurivanjani AT gmail.com) and Shreyas Gokhale (shreyas6gokhale AT gmail.com).

# Application instructions for GSoC-2022

We welcome students to contact relevant mentors before submitting their application into GSoC official website. If in doubt for which project(s) to contact, send a message to jderobot AT gmail.com We recommend browsing previous GSoC student pages to look for ready-to-use projects, and to get an idea of the expected amount of work for a valid GSoC proposal.

## Requirements

* Git experience
* C++ and Python programming experience (depending on the project)

## Programming tests

|    **Project**   |     [#1](https://jderobot.github.io/activities/gsoc/2021#project-1-robotics-academy-new-computer-vision-exercises)     |      [#2](https://jderobot.github.io/activities/gsoc/2021#project-2-robotics-academy-new-drone-based-exercises)      |     [#3](https://jderobot.github.io/activities/gsoc/2021#project-3-robotics-academy-robotic-arm-manipulation-with-moveit)     |     [#4](https://jderobot.github.io/activities/gsoc/2021#project-4-robotics-academy-exercises-on-evolutionary-robotics)     |     [#5](https://jderobot.github.io/activities/gsoc/2021#project-5-improving-visualstates-tool-with-ros2-support-and-web-based-gui)     |     [#6](https://jderobot.github.io/activities/gsoc/2021#project-6-python-robot-applications-in-the-web-browser-extending-the-pyonbrowser-converter-to-js)     |     [#7](https://jderobot.github.io/activities/gsoc/2021#project-7-visualcircuit-tool-digital-electronics-language-for-robot-behaviors)     |     [#8](https://jderobot.github.io/activities/gsoc/2021#project-8-reinforcement-learning-for-autonomous-driving-with-gazebo-and-openai-gym)     |     [#9](https://jderobot.github.io/activities/gsoc/2021#project-8-reinforcement-learning-for-autonomous-driving-with-gazebo-and-openai-gym)     |     [#10](https://jderobot.github.io/activities/gsoc/2021#project-10-robotics-academy-multirobot-version-of-the-amazon-warehouse-exercise-in-ros2)    |
| **Academy (A)** |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |
|    **C++ (B)**   |     X     |     O     |     X     |     X     |     X     |     O     |     X     |     X     |     X     |     X     |
|  **Python (C)**  |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |     X     |
|  **ROS2 (D)**  |     O     |     O     |     O     |     O     |     O     |     -     |     -     |     -     |     -     |     X     |

<br/>

|               Where:                     ||
| * |             Not applicable            |
| X |                Mandatory              |
| O |                Optative               |


Before accepting any proposal all candidates have to do these programming challenges:

- (A) [RoboticsAcademy challenge](https://drive.google.com/file/d/1rNJ5Oyux3w9qNF81_691H89pEw-FCXGv/view?usp=sharing)
- (B) [C++ challenge](https://drive.google.com/file/d/1KKpq6fGGhV99biaJ8l5udADh925nDzZ3/view?usp=sharing)
- (C) [Python challenge](https://drive.google.com/file/d/1cniJXQw3z4DEj8YciO7GnLcmjGPsk53j/view?usp=sharing)
- (D) [ROS2 challenge](https://drive.google.com/file/d/1IJFTtKVcoVykONS73Mh-EQTpKdXgI-bU/view?usp=sharing)

## Send us your information

AFTER doing the programming tests, fill this [web form](https://docs.google.com/forms/d/1puIY7npSsB9_iBKZGPlPlDGpmMFXksCLzApCBVeA_dY) with your information and challenge results. Then you are invited to ask the project mentors about the project details. Maybe we will require more information from you like this:


1. Contact details
   - Name and surname:
   - Country:
   - Email:
   - Public repository/ies:
   - Personal blog (optional):
   - Twitter/Identica/LinkedIn/others:
2. Timeline
   - Now split your project idea in smaller tasks. Quantify the time you think each task needs. Finally, draw a tentative project plan (timeline) including the dates covering all period of GSoC. Don’t forget to include also the days in which you don’t plan to code, because of exams, holidays etc.
   - Do you understand this is a serious commitment, equivalent to a full-time paid summer internship or summer job?
   - Do you have any known time conflicts during the official coding period?
3. Studies
   - What is your School and degree?
   - Would your application contribute to your ongoing studies/degree? If so, how?
4. Programming background
   - Computing experience: operating systems you use on a daily basis, known programming languages, hardware, etc.
   - Robot or Computer Vision programming experience:
   - Other software programming:
5. GSoC participation
   - Have you participated to GSoC before?
   - How many times, which year, which project?
   - Have you applied but were not selected? When?
   - Have you submitted/will you submit another proposal for GSoC 2017 to a different org?



# Previous GSoC students

- [Muhammad Taha](https://theroboticsclub.github.io/colab-gsoc2020-Muhammad_Taha/) (GSoC-2020) VisualCircuit tool, digital electronics language for robot behaviors.
- [Sakshay Mahna](https://theroboticsclub.github.io/colab-gsoc2020-Sakshay_Mahna/) (GSoC-2020) Robotics-Academy exercises on Evolutionary Robotics.
- [Shreyas Gokhale](https://theroboticsclub.github.io/colab-gsoc2020-Shreyas_Gokhale/) (GSoC-2020) Multi-Robot exercises for Robotics Academy In ROS2.
- [Yijia Wu](https://theroboticsclub.github.io/colab-gsoc2020-Yijia_Wu/) (GSoC-2020) Vision-based Industrial Robot Manipulation with MoveIt.
- [Diego Charrez](https://theroboticsclub.github.io/colab-gsoc2020-Diego_Charrez/logbook/) (GSoC-2020) Reinforcement Learning for Autonomous Driving with Gazebo and OpenAI gym.
- [Nikhil Khedekar](https://theroboticsclub.github.io/colab-gsoc2019-Nikhil_Khedekar/) (GSoC-2019) Migration to ROS of drones exercises on JdeRobot Academy
- [Shyngyskhan Abilkassov](https://theroboticsclub.github.io/colab-gsoc2019-Shyngyskhan_Abilkassov) (GSoC-2019) Amazon warehouse exercise on JdeRobot Academy
- [Jeevan Kumar](https://theroboticsclub.github.io/colab-gsoc2019-Jeevan_Kumar/) (GSoC-2019) Improving DetectionSuite DeepLearning tool
- [Baidyanath Kundu](https://theroboticsclub.github.io/colab-gsoc2019-Baidyanath_Kundu/) (GSoC-2019) A parameterized automata Library for VisualStates tool
- [Srinivasan Vijayraghavan](https://theroboticsclub.github.io/colab-gsoc2019-Srinivasan_Vijayraghavan/) (GSoC-2019) Running Python code on the web browser
- [Pankhuri Vanjani](https://theroboticsclub.github.io/colab-gsoc2019-Pankhuri_Vanjani/) (GSoC-2019) Migration of JdeRobot tools to ROS 2
- [Pushkal Katara](https://wiki.jderobot.org/Club-PushkalKatara) (GSoC-2018) VisualStates tool
- [Arsalan Akhter](https://wiki.jderobot.org/Club-aakhter) (GSoC-2018) Robotics-Academy
- [Hanqing Xie](https://wiki.jderobot.org/Club-hanqingxie) (GSoC-2018) Robotics-Academy
- [Sergio Paniego](https://wiki.jderobot.org/Club-spaniego) (GSoC-2018) PyOnArduino tool
- [Jianxiong Cai](https://wiki.jderobot.org/Club-jianxiong) (GSoC-2018) Creating realistic 3D map from online SLAM result
- [Vinay Sharma](https://wiki.jderobot.org/Club-VinaySharma) (GSoC-2018) DeepLearning, DetectionSuite tool
- [Nigel Fernandez](https://wiki.jderobot.org/Ni9elf-colab) GSoC-2017
- [Okan Asik](https://wiki.jderobot.org/Okanasik-colab) GSoC-2017, VisualStates tool
- [S.Mehdi Mohaimanian](https://wiki.jderobot.org/index.php?title=Deep_Reinforcement_Learning_in_Robotic&redirect=no) GSoC-2017
- [Raúl Pérula](https://wiki.jderobot.org/Raulperula-colab) GSoC-2017, Scratch2JdeRobot tool
- [Lihang Li](https://wiki.jderobot.org/Hustcalm-colab): GSoC-2015, Visual SLAM, RGBD, 3D Reconstruction
- [Andrei Militaru](https://wiki.jderobot.org/Militaru92-colab) GSoC-2015, interoperation of ROS and JdeRobot
- [Satyaki Chakraborty](https://wiki.jderobot.org/Chakraborty-colab) GSoC-2015, Interconnection with Android Wear


# How to increase your chances of being selected in GSoC-2022

If you put yourself in the shoes of the mentor that should select the student, you'll immediately realize that there are some behaviors that are usually rewarded. Here's some examples.

1. **Be proactive**: Mentors are more likely to select students that openly discuss the existing ideas and / or propose their own. It is a **bad idea** to just submit your idea only in the Google web site without discussing it, because it won't be noticed.

2. **Demonstrate your skills**: Consider that mentors are being contacted by several students that apply for the same project. A way to show that you are the best candidate, is to demonstrate that you are familiar with the software and you can code. How? Browse the bug tracker (issues in github of JdeRobot project), fix some bugs and propose your patch submitting your PullRequest, and/or ask mentors to challenge you! Moreover, bug fixes are a great way to get familiar with the code.

3. **Demonstrate your intention to stay**: Students that are likely to disappear after GSoC are less likely to be selected. This is because there is no point in developing something that won't be maintained. And moreover, one scope of GSoC is to bring new developers to the community.

# [RTFM](https://xkcd.com/293/)

Read the relevant information about GSoC in the wiki / web pages before asking. Most FAQs have been answered already!

- [Full documentation about GSoC on official website](https://developers.google.com/open-source/gsoc/resources/).
- [FAQ from GSoC web site](https://developers.google.com/open-source/gsoc/faq).
- If you are new to JdeRobot, take the time to familiarize with the [JdeRobot](https://jderobot.org).
